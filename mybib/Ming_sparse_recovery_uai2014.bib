@inproceedings{10.5555/3020751.3020804,
author = {Lin, Ming and Jin, Rong and Zhang, Changshui},
title = {Efficient Sparse Recovery via Adaptive Non-Convex Regularizers with Oracle Property},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The main shortcoming of sparse recovery with a convex regularizer is that it is a
biased estimator and therefore will result in a suboptimal performance in many cases.
Recent studies have shown, both theoretically and empirically, that non-convex regularizer
is able to overcome the biased estimation problem. Although multiple algorithms have
been developed for sparse recovery with non-convex regularization, they are either
computationally demanding or not equipped with the desired properties (i.e. optimal
recovery error, selection consistency and oracle property). In this work, we develop
an algorithm for efficient sparse recovery based on proximal gradient descent. The
key feature of the proposed algorithm is introducing adaptive non-convex regularizers
whose shrinking threshold vary over iterations. The algorithm is compatible with most
popular non-convex regularizers, achieves a geometric convergence rate for the recovery
error, is selection consistent, and most importantly has the oracle property. Based
on the proposed framework, we suggest to use a so-called ACCQ regularizer, which is
equivalent to zero proximal projection gap adaptive hard-thresholding. Experiments
with both synthetic data sets and real images verify both the efficiency and effectiveness
of the proposed method compared to the state-of-the-art methods for sparse recovery.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {505â€“514},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}